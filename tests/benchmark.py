"""
EPANET-Turbo æ€§èƒ½åŸºå‡†æµ‹è¯•

å¯¹æ¯” Open-Once/Run-Many + Batch Setter ä¸ä¼ ç»Ÿæ–¹å¼çš„æ€§èƒ½å·®å¼‚
"""

import time
import numpy as np
from pathlib import Path

from epanet_turbo import simulate, ModelContext

def benchmark_open_once(inp_path: str, n_scenarios: int = 100):
    """ä½¿ç”¨ Open-Once/Run-Many æ¨¡å¼è¿è¡Œå¤šåœºæ™¯"""
    print(f"\nğŸš€ Open-Once/Run-Many Mode ({n_scenarios} scenarios)")
    
    t0 = time.perf_counter()
    with ModelContext(inp_path) as ctx:
        # è·å–å‰ä¸¤ä¸ªèŠ‚ç‚¹ ID
        node_ids = ctx._node_ids[:2]
        for i in range(n_scenarios):
            # éšæœºä¿®æ”¹éœ€æ°´é‡
            demands = {
                nid: 100 + np.random.rand() * 200 for nid in node_ids
            }
            res = ctx.run_scenario(demands=demands)
    
    elapsed = time.perf_counter() - t0
    per_scenario = elapsed / n_scenarios * 1000
    print(f"   Total: {elapsed:.3f}s")
    print(f"   Per scenario: {per_scenario:.2f}ms")
    return elapsed

def benchmark_open_each(inp_path: str, n_scenarios: int = 100):
    """ä¼ ç»Ÿæ–¹å¼ï¼šæ¯æ¬¡éƒ½é‡æ–°æ‰“å¼€æ–‡ä»¶"""
    print(f"\nğŸŒ Open-Each Mode ({n_scenarios} scenarios)")
    print("   (éœ€è¦ä¿®æ”¹ INP æ–‡ä»¶ï¼Œè¿™é‡Œç”¨ç®€åŒ–æµ‹è¯•)")
    
    t0 = time.perf_counter()
    for i in range(n_scenarios):
        # æ¯æ¬¡éƒ½é‡æ–°æ‰“å¼€
        with ModelContext(inp_path) as ctx:
            node_ids = ctx._node_ids[:2]
            demands = {
                nid: 100 + np.random.rand() * 200 for nid in node_ids
            }
            res = ctx.run_scenario(demands=demands, reset=False)
    
    elapsed = time.perf_counter() - t0
    per_scenario = elapsed / n_scenarios * 1000
    print(f"   Total: {elapsed:.3f}s")
    print(f"   Per scenario: {per_scenario:.2f}ms")
    return elapsed

def main():
    print("=" * 60)
    print("  EPANET-Turbo v1.1 Performance Benchmark")
    print("=" * 60)
    
    # é¦–é€‰å¤§è§„æ¨¡ç½‘ç»œ
    large_inp = Path(r"d:\Project\å¼€å‘é¡¹ç›®\EPANET\Example\gz_clean.inp")
    small_inp = Path(__file__).parent.parent / "examples" / "Net1.inp"
    
    if large_inp.exists():
        inp_path = large_inp
        n_scenarios = 5  # éå¸¸å¤§çš„ç½‘ç»œï¼Œè·‘ 5 ä¸ªåœºæ™¯ä»¥èŠ‚çœæ—¶é—´
        print(f"\nğŸ“ Large Network: {inp_path.name}")
    elif small_inp.exists():
        inp_path = small_inp
        n_scenarios = 100
        print(f"\nğŸ“ Small Network: {inp_path.name}")
    else:
        print("âŒ No INP file found")
        return
    
    # é¢„çƒ­
    print("\nâ³ Warming up...")
    with ModelContext(str(inp_path)) as ctx:
        ctx.run_scenario()
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    t_once = benchmark_open_once(str(inp_path), n_scenarios)
    t_each = benchmark_open_each(str(inp_path), n_scenarios)
    
    # è®¡ç®—æé€Ÿæ¯”
    speedup = t_each / t_once
    
    print("\n" + "=" * 60)
    print(f"  ğŸ“Š Result: Open-Once is {speedup:.1f}x faster")
    print("=" * 60)
    
    # æ£€æŸ¥ batch setter æ˜¯å¦å¯ç”¨
    with ModelContext(str(inp_path)) as ctx:
        if ctx._use_batch_setter:
            print("\nâœ… Batch Setter: ENABLED")
        else:
            print("\nâš ï¸  Batch Setter: DISABLED (fallback mode)")

if __name__ == "__main__":
    main()
